{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfe37963-1af6-44fc-a841-8e462443f5e6",
   "metadata": {},
   "source": [
    "## 专家知识工作者\n",
    "\n",
    "### 一个作为专家知识工作者的问答代理\n",
    "### 供保险科技公司 顶云 的员工使用\n",
    "### 该代理需要准确，并且解决方案应低成本。\n",
    "\n",
    "本项目将使用 RAG（检索增强生成）以确保我们的问答助手具有高准确性。\n",
    "\n",
    "## 今天：\n",
    "\n",
    "- Part A：我们将文档切分为 CHUNKS（分块）\n",
    "- Part B：将 CHUNKS 编码为 VECTORS（向量）并存入 Chroma\n",
    "- Part C：可视化向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2aa4d5cd-b452-4fd5-a9fd-569f54296f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-huggingface in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (1.2.0)\n",
      "Requirement already satisfied: sentence-transformers in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (5.2.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.33.4 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langchain-huggingface) (0.36.0)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.2.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langchain-huggingface) (1.2.6)\n",
      "Requirement already satisfied: tokenizers<1.0.0,>=0.19.1 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langchain-huggingface) (0.21.1)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (2024.12.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (1.2.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.6.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (2.11.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (9.1.2)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.12.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.23.0)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (4.9.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.4.0)\n",
      "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from sentence-transformers) (4.51.3)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from sentence-transformers) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (2.4.0)\n",
      "Requirement already satisfied: sympy!=1.13.2,>=1.13.1 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from sympy!=1.13.2,>=1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "#如果运行下面import出现找不到模块错误时（langchain-huggingface），运行下这个\n",
    "!python -m pip install -U langchain-huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0769edb3",
   "metadata": {},
   "source": [
    "### Part A：将文档切分为分块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba2779af-84ef-4227-9e9e-6eaf0df87e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "802137aa-8a74-45e0-a487-d1974927d7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key 存在且开头为 sk-proj-\n"
     ]
    }
   ],
   "source": [
    "# 价格是公司需要考虑的因素，因此我们使用一个低成本模型\n",
    "\n",
    "MODEL = \"gpt-4.1-nano\"\n",
    "db_name = \"vector_db\"\n",
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key 存在且开头为 {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key 未设置\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58c85082-e417-4708-9efe-81a5d55d1424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在知识库中找到了 76 个文件\n",
      "知识库总字符数: 304,434\n"
     ]
    }
   ],
   "source": [
    "# 所有文档一共有多少字符？\n",
    "\n",
    "knowledge_base_path = \"knowledge-base/**/*.md\"\n",
    "files = glob.glob(knowledge_base_path, recursive=True)\n",
    "print(f\"在知识库中找到了 {len(files)} 个文件\")\n",
    "\n",
    "entire_knowledge_base = \"\"\n",
    "\n",
    "for file_path in files:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        entire_knowledge_base += f.read()\n",
    "        entire_knowledge_base += \"\\n\\n\"\n",
    "\n",
    "print(f\"知识库总字符数: {len(entire_knowledge_base):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b53a099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 总数: 63,555\n"
     ]
    }
   ],
   "source": [
    "# 所有文档一共有多少 token？\n",
    "\n",
    "encoding = tiktoken.get_encoding(\"o200k_base\")\n",
    "tokens = encoding.encode(entire_knowledge_base)\n",
    "token_count = len(tokens)\n",
    "print(f\"token 总数: {token_count:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee78efcb-60fe-449e-a944-40bab26261af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已加载 76 个文档\n"
     ]
    }
   ],
   "source": [
    "# 使用 LangChain 的 loader 加载知识库中的所有内容\n",
    "\n",
    "folders = glob.glob(\"knowledge-base/*\")\n",
    "\n",
    "documents = []\n",
    "for folder in folders:\n",
    "    doc_type = os.path.basename(folder)\n",
    "    loader = DirectoryLoader(folder, glob=\"**/*.md\", loader_cls=TextLoader, loader_kwargs={'encoding': 'utf-8'})\n",
    "    folder_docs = loader.load()\n",
    "    for doc in folder_docs:\n",
    "        doc.metadata[\"doc_type\"] = doc_type\n",
    "        documents.append(doc)\n",
    "\n",
    "print(f\"已加载 {len(documents)} 个文档\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68dab1ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'knowledge-base/products/Rellm.md', 'doc_type': 'products'}, page_content=\"# Product Summary\\n\\n# Rellm: AI-Powered Enterprise Reinsurance Solution\\n\\n## Summary\\n\\nRellm is an innovative enterprise reinsurance product developed by Insurellm, designed to transform the way reinsurance companies operate. Harnessing the power of artificial intelligence, Rellm offers an advanced platform that redefines risk management, enhances decision-making processes, and optimizes operational efficiencies within the reinsurance industry. With seamless integrations and robust analytics, Rellm enables insurers to proactively manage their portfolios and respond to market dynamics with agility.\\n\\n## Features\\n\\n### AI-Driven Analytics\\nRellm utilizes cutting-edge AI algorithms to provide predictive insights into risk exposures, enabling users to forecast trends and make informed decisions. Its real-time data analysis empowers reinsurance professionals with actionable intelligence.\\n\\n### Seamless Integrations\\nRellm's architecture is designed for effortless integration with existing systems. Whether it's policy management, claims processing, or financial reporting, Rellm connects seamlessly with diverse data sources to create a unified ecosystem.\\n\\n### Risk Assessment Module\\nThe comprehensive risk assessment module within Rellm allows insurers to evaluate risk profiles accurately. By leveraging historical data and advanced modeling techniques, Rellm provides a clear picture of potential liabilities and expected outcomes.\\n\\n### Customizable Dashboard\\nRellm features a customizable dashboard that presents key metrics and performance indicators in an intuitive interface. Users can tailor their view to focus on what matters most to their business, enhancing user experience and productivity.\\n\\n### Regulatory Compliance Tools\\nRellm includes built-in compliance tracking features to help organizations meet local and international regulatory standards. This ensures that reinsurance practices remain transparent and accountable.\\n\\n### Client and Broker Portals\\nRellm offers dedicated portals for both clients and brokers, facilitating real-time communication and documentation sharing. This strengthens partnerships and drives operational excellence across the board.\\n\\n## Pricing\\n\\nInsurellm offers flexible pricing plans for Rellm to cater to various business needs:\\n\\n- **Basic Plan**: $5,000/month\\n  - Includes access to core features and standard integrations.\\n  \\n- **Professional Plan**: $10,000/month\\n  - Includes all features, advanced integrations, and priority customer support.\\n  \\n- **Enterprise Plan**: Custom pricing\\n  - Tailored solutions with personalized features, extensive integrations, and dedicated account management.\\n\\nJoin the growing number of organizations leveraging Rellm to enhance their reinsurance processes while driving profitability and compliance. \\n\\n## 2025-2026 Roadmap\\n\\nAt Insurellm, we are committed to the continuous improvement of Rellm. Our roadmap for 2025-2026 includes:\\n\\n- **Q3 2025**: \\n  - Launch of the Rellm Mobile App for on-the-go insights and management.\\n  - Introduction of augmented reality (AR) features for interactive risk assessments.\\n\\n- **Q1 2026**: \\n  - Deployment of advanced machine learning models for even more accurate risk predictions.\\n  - Expansion of integration capabilities to support emerging technologies in the insurance sector.\\n\\n- **Q3 2026**: \\n  - Release of a community platform for Rellm users to exchange insights, tips, and best practices.\\n  - Launch of Rellm 2.0, featuring enhanced user interface and premium features based on user feedback.\\n\\nExperience the future of reinsurance with Rellm, where innovation meets reliability. Let Insurellm help you navigate the complexities of the reinsurance market smarter and faster.\")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25987306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已切分为 532 个分块\n",
      "第一个分块:\n",
      "\n",
      "page_content='# Product Summary\n",
      "\n",
      "# Rellm: AI-Powered Enterprise Reinsurance Solution\n",
      "\n",
      "## Summary\n",
      "\n",
      "Rellm is an innovative enterprise reinsurance product developed by Insurellm, designed to transform the way reinsurance companies operate. Harnessing the power of artificial intelligence, Rellm offers an advanced platform that redefines risk management, enhances decision-making processes, and optimizes operational efficiencies within the reinsurance industry. With seamless integrations and robust analytics, Rellm enables insurers to proactively manage their portfolios and respond to market dynamics with agility.\n",
      "\n",
      "## Features' metadata={'source': 'knowledge-base/products/Rellm.md', 'doc_type': 'products'}\n"
     ]
    }
   ],
   "source": [
    "# 使用 RecursiveCharacter文本Splitter 将文档切分为分块\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"已切分为 {len(chunks)} 个分块\")\n",
    "print(f\"第一个分块:\\n\\n{chunks[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9eb209db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'knowledge-base/contracts/Contract with National Claims Network for Claimllm.md', 'doc_type': 'contracts'}, page_content=\"7. **Business Continuity:** Insurellm provides disaster recovery with 4-hour RTO (Recovery Time Objective) and 1-hour RPO (Recovery Point Objective).\\n\\n---\\n\\n## Renewal\\n\\nThis agreement includes a mutual 120-day renewal notice period. National Claims Network receives guaranteed enterprise pricing for renewal equal to or better than new enterprise customers at renewal time. Contract may be extended in 12-month increments with mutual written agreement.\\n\\n---\\n\\n## Features\\n\\nNational Claims Network will receive the complete Claimllm Enterprise suite:\\n\\n1. **Unlimited Claims Processing:** No volume restrictions, supporting National's processing of 100,000+ claims annually with scalability to 500,000+ claims as business grows.\\n\\n2. **White-Label Platform:** Complete branding customization including:\\n   - Custom domain names (claims.nationalclaimsnetwork.com)\\n   - Branded mobile apps (iOS and Android)\\n   - Customized email templates and communications\\n   - Co-branded claimant portals\")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecee2169",
   "metadata": {},
   "source": [
    "### Part B：生成向量并存入 Chroma\n",
    "\n",
    "在第 3 周，你创建了 Hugging Face 账号并获得了 HF_TOKEN\n",
    "\n",
    "此时，你可能想把它加入到 `.env` 文件里，并运行 `load_dotenv(override=True)`\n",
    "\n",
    "（实际上这不一定需要。）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730711a9-6ffe-4eee-8f48-d6cfb7314905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选择一个 embedding（向量化）模型\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "#embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "if os.path.exists(db_name):\n",
    "    Chroma(persist_directory=db_name, embedding_function=embeddings).delete_collection()\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=chunks, embedding=embeddings, persist_directory=db_name)\n",
    "print(f\"向量库已创建，包含 {vectorstore._collection.count()} 条文档\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252f17e9-3529-4e81-996c-cfa9f08e75a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 让我们检查一下向量\n",
    "\n",
    "collection = vectorstore._collection\n",
    "count = collection.count()\n",
    "\n",
    "sample_embedding = collection.get(limit=1, include=[\"embeddings\"])[\"embeddings\"][0]\n",
    "dimensions = len(sample_embedding)\n",
    "print(f\"向量库中有 {count:,} 个向量，每个向量维度为 {dimensions:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30096a7",
   "metadata": {},
   "source": [
    "### Part C：可视化！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d48dcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预处理\n",
    "\n",
    "result = collection.get(include=['embeddings', 'documents', 'metadatas'])\n",
    "vectors = np.array(result['embeddings'])\n",
    "documents = result['documents']\n",
    "metadatas = result['metadatas']\n",
    "doc_types = [metadata['doc_type'] for metadata in metadatas]\n",
    "colors = [['blue', 'green', 'red', 'orange'][['products', 'employees', 'contracts', 'company'].index(t)] for t in doc_types]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8decb0-d9b0-4d51-8402-7a6174d22159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 人类更容易在二维中进行可视化！\n",
    "# 使用 t-SNE 将向量降维到 2D\n",
    "# （t 分布随机邻域嵌入）\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "reduced_vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "# 创建二维散点图\n",
    "fig = go.Figure(data=[go.Scatter(\n",
    "    x=reduced_vectors[:, 0],\n",
    "    y=reduced_vectors[:, 1],\n",
    "    mode='markers',\n",
    "    marker=dict(size=5, color=colors, opacity=0.8),\n",
    "    text=[f\"类型: {t}<br>文本: {d[:100]}...\" for t, d in zip(doc_types, documents)],\n",
    "    hoverinfo='text'\n",
    ")])\n",
    "\n",
    "fig.update_layout(title='2D Chroma 向量库可视化',\n",
    "    scene=dict(xaxis_title='x',yaxis_title='y'),\n",
    "    width=800,\n",
    "    height=600,\n",
    "    margin=dict(r=20, b=10, l=10, t=40)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7310c9c8-03c1-4efc-a104-5e89aec6db1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 再试试 3D！\n",
    "\n",
    "tsne = TSNE(n_components=3, random_state=42)\n",
    "reduced_vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "# 创建三维散点图\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=reduced_vectors[:, 0],\n",
    "    y=reduced_vectors[:, 1],\n",
    "    z=reduced_vectors[:, 2],\n",
    "    mode='markers',\n",
    "    marker=dict(size=5, color=colors, opacity=0.8),\n",
    "    text=[f\"类型: {t}<br>文本: {d[:100]}...\" for t, d in zip(doc_types, documents)],\n",
    "    hoverinfo='text'\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title='3D Chroma 向量库可视化',\n",
    "    scene=dict(xaxis_title='x', yaxis_title='y', zaxis_title='z'),\n",
    "    width=900,\n",
    "    height=700,\n",
    "    margin=dict(r=10, b=10, l=10, t=40)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65489941",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
