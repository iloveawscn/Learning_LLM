{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75e2ef28-594f-4c18-9d22-c6b8cd40ead2",
   "metadata": {},
   "source": [
    "# 第 3 天 - 对话式 AI - 即聊天机器人！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e39cd8-ec79-4e3e-9c26-5659d42d0861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入库\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231605aa-fccb-447e-89cf-8b187444536a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载名为 .env 文件中的环境变量\n",
    "# 打印密钥前缀以帮助调试\n",
    "\n",
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API 密钥存在，前缀为 {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"未设置 OpenAI API 密钥\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API 密钥存在，前缀为 {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"未设置 Anthropic API 密钥\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API 密钥存在，前缀为 {google_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"未设置 Google API 密钥\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6541d58e-2297-4de1-b1f7-77da1b98b8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化\n",
    "\n",
    "openai = OpenAI()\n",
    "MODEL = 'gpt-4o-mini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16839b5-c03b-4d9d-add6-87a0f6f37575",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"你是一个乐于助人的助手\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e97227-f162-4d1a-a0b2-345ff248cbe7",
   "metadata": {},
   "source": [
    "# 请阅读！\n",
    "Gradio 已经升级了！现在它会以完全符合 OpenAI 的格式传入 `history`，非常适合我们直接发送给 OpenAI。\n",
    "\n",
    "新版本中，开发者可以在创建 gr.ChatInterface 时通过设置参数 type=\"messages\"，让传递给函数的 history 直接就是 OpenAI API 所需的“消息字典列表”格式，形如 [{\"role\": \"user\", \"content\": \"...\"}, {\"role\": \"assistant\", \"content\": \"...\"}]。\n",
    "\n",
    "我们将编写一个函数 `chat(message, history)`，其中：\n",
    "**message** 是要使用的提示\n",
    "**history** 是过去的对话，采用 OpenAI 格式\n",
    "\n",
    "我们将结合系统消息、历史记录和最新消息，然后调用 OpenAI。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eacc8a4-4b48-4358-9e06-ce0020041bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我们可以轻松地创建这个调用 OpenAI 的函数\n",
    "# 现在准备 OpenAI 的输入只需要 1 行代码！\n",
    "\n",
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "\n",
    "    print(\"history是：\")\n",
    "    print(history)\n",
    "    print(\"而 messages 是：\")\n",
    "    print(messages)\n",
    "\n",
    "    stream = openai.chat.completions.create(model=MODEL, messages=messages, stream=True)\n",
    "\n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        yield response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1334422a-808f-4147-9c4c-57d63d9780d0",
   "metadata": {},
   "source": [
    "## 接着进入 Gradio 的魔法世界！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0866ca56-100a-44ab-8bd0-1568feaf6bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f91b414-8bab-472d-b9c9-3fa51259bdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"你是一家服装店里乐于助人的店员。你应该尝试温和地鼓励 \\\n",
    "顾客试穿正在打折的商品。帽子六折，其他大部分商品五折。 \\\n",
    "例如，如果顾客说‘我想买一顶帽子’， \\\n",
    "你可以回复类似‘太好了 - 我们有很多帽子 - 其中有几款正在参加我们的促销活动。’\\\n",
    "如果顾客不确定要买什么，鼓励他们买帽子。\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5be3ec-c26c-42bc-ac16-c39d369883f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "\n",
    "    stream = openai.chat.completions.create(model=MODEL, messages=messages, stream=True)\n",
    "\n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        yield response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413e9e4e-7836-43ac-a0c3-e1ab5ed6b136",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75f0ffa-55c8-4152-b451-945021676837",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message += \"\\n如果顾客问起鞋子，你应该回答说鞋子今天不打折， \\\n",
    "但要提醒顾客看看帽子！\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c602a8dd-2df7-4eb7-b539-4e01865a6351",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a987a66-1061-46d6-a83a-a30859dc88bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 我还改进了此函数的结构\n",
    "\n",
    "def chat(message, history):\n",
    "\n",
    "    relevant_system_message = system_message\n",
    "    if 'belt' in message or '皮带' in message:\n",
    "        relevant_system_message += \" 本店不卖皮带；如果被问到皮带，请务必指出其他在售商品。\"\n",
    "    \n",
    "    messages = [{\"role\": \"system\", \"content\": relevant_system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "\n",
    "    stream = openai.chat.completions.create(model=MODEL, messages=messages, stream=True)\n",
    "\n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        yield response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20570de2-eaad-42cc-a92c-c779d71b48b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a57ee0-b945-48a7-a024-01b56a5d4b3e",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../business.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#181;\">商业应用</h2>\n",
    "            <span style=\"color:#181;\">对话式助手当然是生成式 AI 一个非常常见的用例，而最新的前沿模型在细致入微的对话方面表现得非常出色。Gradio 使得拥有用户界面变得容易。我们涵盖的另一个关键技能是如何使用提示来提供上下文、信息和示例。\n",
    "<br/><br/>\n",
    "考虑如何将 AI 助手应用于您的业务，并为自己制作一个原型。使用系统提示为您的业务提供背景，并为 LLM 设定基调。</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfb9e21-df67-4c2b-b952-5e7e7961b03d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
