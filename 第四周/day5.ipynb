{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a6ab9a2-28a2-445d-8512-a0dc8d1b54e9",
   "metadata": {},
   "source": [
    "# 代码生成器\n",
    "\n",
    "需求：使用前沿模型将 Python 代码生成为高性能 C++ 代码\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ccb926-7b49-44a4-99ab-8ef20b5778c0",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../important.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">提醒：执行 C++ 或 Rust 代码是可选的</h2>\n",
    "            <span style=\"color:#f71;\">作为替代方案，你可以在昨天提供的网站上运行它</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90e04a2-5b8a-4fd5-9db8-27c02f033313",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../important.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h1 style=\"color:#900;\">重要提示</h1>\n",
    "            <span style=\"color:#900;\">\n",
    "            在本实验中，我使用高端模型 GPT 5、Claude 4.5 Sonnet、Gemini 2.5 Pro、Grok 4，这些是价格稍高的模型。成本仍然很低，但如果您想将成本保持在极低水平，请选择 gpt-5-nano 等低成本模型。\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e610bf56-a46e-4aff-8de1-ab49d62b1ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入库\n",
    "\n",
    "import os\n",
    "import io\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr\n",
    "import subprocess\n",
    "from IPython.display import Markdown, display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f672e1c-87e9-4865-b760-370fa605e614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API 密钥存在，开头为 sk-proj-\n",
      "Anthropic API 密钥存在，开头为 sk-ant-\n",
      "Google API 密钥存在，开头为 AI\n",
      "Grok API 密钥存在，开头为 xai-\n",
      "Groq API 密钥存在，开头为 gsk_\n",
      "未设置 OpenRouter API 密钥（此项为可选）\n",
      "siliconcloud API 密钥存在，开头为 sk-t\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "grok_api_key = os.getenv('GROK_API_KEY')\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "openrouter_api_key = os.getenv('OPENROUTER_API_KEY')\n",
    "siliconcloud_api_key = os.getenv('SILICONCLOUD_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API 密钥存在，开头为 {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"未设置 OpenAI API 密钥\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API 密钥存在，开头为 {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"未设置 Anthropic API 密钥（此项为可选）\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API 密钥存在，开头为 {google_api_key[:2]}\")\n",
    "else:\n",
    "    print(\"未设置 Google API 密钥（此项为可选）\")\n",
    "\n",
    "if grok_api_key:\n",
    "    print(f\"Grok API 密钥存在，开头为 {grok_api_key[:4]}\")\n",
    "else:\n",
    "    print(\"未设置 Grok API 密钥（此项为可选）\")\n",
    "\n",
    "if groq_api_key:\n",
    "    print(f\"Groq API 密钥存在，开头为 {groq_api_key[:4]}\")\n",
    "else:\n",
    "    print(\"未设置 Groq API 密钥（此项为可选）\")\n",
    "\n",
    "if openrouter_api_key:\n",
    "    print(f\"OpenRouter API 密钥存在，开头为 {openrouter_api_key[:6]}\")\n",
    "else:\n",
    "    print(\"未设置 OpenRouter API 密钥（此项为可选）\")\n",
    "\n",
    "if siliconcloud_api_key:\n",
    "    print(f\"siliconcloud API 密钥存在，开头为 {siliconcloud_api_key[:4]}\")\n",
    "else:\n",
    "    print(\"未设置 siliconcloud API 密钥（此项为可选）\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59863df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 连接到客户端库\n",
    "\n",
    "openai = OpenAI()\n",
    "\n",
    "anthropic_url = \"https://api.anthropic.com/v1/\"\n",
    "gemini_url = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "grok_url = \"https://api.x.ai/v1\"\n",
    "groq_url = \"https://api.groq.com/openai/v1\"\n",
    "ollama_url = \"http://localhost:11434/v1\"\n",
    "openrouter_url = \"https://openrouter.ai/api/v1\"\n",
    "siliconcloud_url = \"https://api.siliconflow.cn/v1\"\n",
    "\n",
    "anthropic = OpenAI(api_key=anthropic_api_key, base_url=anthropic_url)\n",
    "gemini = OpenAI(api_key=google_api_key, base_url=gemini_url)\n",
    "grok = OpenAI(api_key=grok_api_key, base_url=grok_url)\n",
    "groq = OpenAI(api_key=groq_api_key, base_url=groq_url)\n",
    "ollama = OpenAI(api_key=\"ollama\", base_url=ollama_url)\n",
    "openrouter = OpenAI(api_key=openrouter_api_key, base_url=openrouter_url)\n",
    "siliconcloud = OpenAI(api_key=siliconcloud_api_key, base_url=siliconcloud_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8aa149ed-9298-4d69-8fe2-8f5de0f667da",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"gpt-5\", \"claude-sonnet-4-5-20250929\", \"gemini-2.5-pro\", \"openai/gpt-oss-120b\", \"deepseek-ai/DeepSeek-V3.2-Exp\", \"openai/gpt-oss-20b\", \"Qwen/Qwen3-Coder-30B-A3B-Instruct\", \"qwen2.5-coder\"]\n",
    "\n",
    "clients = {\"gpt-5\": openai, \"claude-sonnet-4-5-20250929\": anthropic, \"gemini-2.5-pro\": gemini, \"openai/gpt-oss-120b\": groq, \"deepseek-ai/DeepSeek-V3.2-Exp\": siliconcloud, \"openai/gpt-oss-20b\": groq, \"Qwen/Qwen3-Coder-30B-A3B-Instruct\": siliconcloud, \"qwen2.5-coder\": ollama}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68c1f1be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'installed': True,\n",
       " 'rustc': {'path': '/opt/homebrew/bin/rustc',\n",
       "  'version': 'rustc 1.91.1 (ed61e7d7e 2025-11-07) (Homebrew)',\n",
       "  'host_triple': 'aarch64-apple-darwin',\n",
       "  'release': '1.91.1',\n",
       "  'commit_hash': 'ed61e7d7e242494fb7057f2657300d9e77bb4fcb'},\n",
       " 'cargo': {'path': '/opt/homebrew/bin/cargo',\n",
       "  'version': 'cargo 1.91.1 (Homebrew)'},\n",
       " 'rustup': {'path': '',\n",
       "  'version': '',\n",
       "  'active_toolchain': '',\n",
       "  'default_toolchain': '',\n",
       "  'toolchains': [],\n",
       "  'targets_installed': []},\n",
       " 'rust_analyzer': {'path': ''},\n",
       " 'env': {'CARGO_HOME': '',\n",
       "  'RUSTUP_HOME': '',\n",
       "  'RUSTFLAGS': '',\n",
       "  'CARGO_BUILD_TARGET': ''},\n",
       " 'execution_examples': ['\"/opt/homebrew/bin/cargo\" build',\n",
       "  '\"/opt/homebrew/bin/cargo\" run',\n",
       "  '\"/opt/homebrew/bin/cargo\" test',\n",
       "  '\"/opt/homebrew/bin/rustc\" hello.rs -o hello']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from system_info import retrieve_system_info, rust_toolchain_info\n",
    "\n",
    "system_info = retrieve_system_info()\n",
    "rust_info = rust_toolchain_info()\n",
    "rust_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8bd44f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "不需要安装。你的系统已安装 Rust 工具链：\n",
       "- rustc: /opt/homebrew/bin/rustc (1.91.1)\n",
       "- cargo: /opt/homebrew/bin/cargo (1.91.1)\n",
       "\n",
       "最简单的一次性编译并运行单文件\n",
       "```sh\n",
       "/opt/homebrew/bin/rustc main.rs -O -o main\n",
       "./main\n",
       "```\n",
       "\n",
       "Python 中为“尽可能最快运行时性能”的命令（编译可慢）\n",
       "```python\n",
       "compile_command = [\n",
       "    \"/opt/homebrew/bin/rustc\",\n",
       "    \"-C\", \"opt-level=3\",\n",
       "    \"-C\", \"target-cpu=native\",\n",
       "    \"-C\", \"lto=fat\",\n",
       "    \"-C\", \"codegen-units=1\",\n",
       "    \"-C\", \"panic=abort\",\n",
       "    \"main.rs\",\n",
       "    \"-o\", \"main\",\n",
       "]\n",
       "\n",
       "run_command = [\"./main\"]\n",
       "```\n",
       "\n",
       "说明：\n",
       "- 以上编译参数偏向极致运行时性能（牺牲编译时间）：O3、LTO(fat)、单代码生成单元、panic 直接 abort、按本机 CPU 指令集优化。\n",
       "- 如遇链接过慢或内存压力大，可将 lto=fat 改为 lto=thin。"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "message = f\"\"\"\n",
    "这是我的计算机系统信息报告。\n",
    "我想运行 Rust 编译器编译一个名为 main.rs 的单个 Rust 文件，然后以最简单的方式执行它。\n",
    "请回复我是否需要安装 Rust 工具链来执行此操作。如果是，请提供最简单的分步说明。\n",
    "\n",
    "如果我已经设置好可以编译 Rust 代码，那么我想在 Python 中运行类似下面的代码来编译和执行代码：\n",
    "```python\n",
    "compile_command = # 这里填写内容 - 以实现最快的运行时性能\n",
    "compile_result = subprocess.run(compile_command, check=True, text=True, capture_output=True)\n",
    "run_command = # 这里填写内容\n",
    "run_result = subprocess.run(run_command, check=True, text=True, capture_output=True)\n",
    "return run_result.stdout\n",
    "```\n",
    "请确切告诉我 compile_command 和 run_command 应该用什么。\n",
    "请牢记最大可能的运行时性能；编译时间可以慢。此平台的尽可能最快运行时性能是关键。\n",
    "请用 markdown 回复命令。\n",
    "\n",
    "系统信息：\n",
    "{system_info}\n",
    "\n",
    "Rust 工具链信息：\n",
    "{rust_info}\n",
    "\"\"\"\n",
    "\n",
    "response = openai.chat.completions.create(model=models[0], messages=[{\"role\": \"user\", \"content\": message}])\n",
    "display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e92c12",
   "metadata": {},
   "source": [
    "## 对于 C++，请用昨天的命令覆盖此处，或者对于 Rust，使用新命令\n",
    "\n",
    "或者直接像昨天一样使用网站：\n",
    "\n",
    " https://www.programiz.com/cpp-programming/online-compiler/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d734a634",
   "metadata": {},
   "outputs": [],
   "source": [
    "compile_command = [\n",
    "    \"/opt/homebrew/bin/rustc\", \"main.rs\",\n",
    "    \"-C\", \"opt-level=3\",\n",
    "    \"-C\", \"lto=fat\",\n",
    "    \"-C\", \"codegen-units=1\",\n",
    "    \"-C\", \"target-cpu=native\",\n",
    "    \"-C\", \"panic=abort\",\n",
    "    \"-C\", \"strip=symbols\",\n",
    "    \"-o\", \"main\",\n",
    "]\n",
    "run_command = [\"./main\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b0a437",
   "metadata": {},
   "source": [
    "## 现在，继续主要任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6896636f-923e-4a2c-9d6c-fac07828a201",
   "metadata": {},
   "outputs": [],
   "source": [
    "language = \"Rust\" # 或 \"C++\"\n",
    "extension = \"rs\" if language == \"Rust\" else \"cpp\"\n",
    "\n",
    "system_prompt = f\"\"\"\n",
    "你的任务是将 Python 代码转换为高性能 {language} 代码。\n",
    "仅回复 {language} 代码。除偶尔的注释外，不要提供任何解释。\n",
    "{language} 响应需要产生相同的输出，并以尽可能快的时间运行。\n",
    "\"\"\"\n",
    "\n",
    "def user_prompt_for(python):\n",
    "    return f\"\"\"\n",
    "将此 Python 代码移植到 {language}，采用产生相同输出且耗时最少的最快实现。\n",
    "系统信息如下：\n",
    "{system_info}\n",
    "你的响应将被写入名为 main.{language} 的文件，然后编译并执行；编译命令是：\n",
    "{compile_command}\n",
    "仅回复 {language} 代码。\n",
    "要移植的 Python 代码：\n",
    "\n",
    "```python\n",
    "{python}\n",
    "```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e7b3546-57aa-4c29-bc5d-f211970d04eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages_for(python):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(python)}\n",
    "    ]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6190659-f54c-4951-bef4-4960f8e51cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_output(code):\n",
    "    with open(f\"main.{extension}\", \"w\") as f:\n",
    "        f.write(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7d2fea8-74c6-4421-8f1e-0e76d5b201b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def port(model, python):\n",
    "    client = clients[model]\n",
    "    reasoning_effort = \"high\" if 'gpt' in model else None\n",
    "    response = client.chat.completions.create(model=model, messages=messages_for(python), reasoning_effort=reasoning_effort)\n",
    "    reply = response.choices[0].message.content\n",
    "    reply = reply.replace('```cpp','').replace('```rust','').replace('```','')\n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fe1cd4b-d2c5-4303-afed-2115a3fef200",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_python(code):\n",
    "    globals_dict = {\"__builtins__\": __builtins__}\n",
    "\n",
    "    buffer = io.StringIO()\n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = buffer\n",
    "\n",
    "    try:\n",
    "        exec(code, globals_dict)\n",
    "        output = buffer.getvalue()\n",
    "    except Exception as e:\n",
    "        output = f\"Error: {e}\"\n",
    "    finally:\n",
    "        sys.stdout = old_stdout\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4194e40c-04ab-4940-9d64-b4ad37c5bb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 GPT 5 的命令\n",
    "\n",
    "def compile_and_run(code):\n",
    "    write_output(code)\n",
    "    try:\n",
    "        subprocess.run(compile_command, check=True, text=True, capture_output=True)\n",
    "        run_result = subprocess.run(run_command, check=True, text=True, capture_output=True)\n",
    "        return run_result.stdout\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        return f\"发生错误：\\n{e.stderr}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9658eb3-41aa-4d77-a74d-1abacc763c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_hard = \"\"\"# 注意支持大数\n",
    "\n",
    "def lcg(seed, a=1664525, c=1013904223, m=2**32):\n",
    "    value = seed\n",
    "    while True:\n",
    "        value = (a * value + c) % m\n",
    "        yield value\n",
    "        \n",
    "def max_subarray_sum(n, seed, min_val, max_val):\n",
    "    lcg_gen = lcg(seed)\n",
    "    random_numbers = [next(lcg_gen) % (max_val - min_val + 1) + min_val for _ in range(n)]\n",
    "    max_sum = float('-inf')\n",
    "    for i in range(n):\n",
    "        current_sum = 0\n",
    "        for j in range(i, n):\n",
    "            current_sum += random_numbers[j]\n",
    "            if current_sum > max_sum:\n",
    "                max_sum = current_sum\n",
    "    return max_sum\n",
    "\n",
    "def total_max_subarray_sum(n, initial_seed, min_val, max_val):\n",
    "    total_sum = 0\n",
    "    lcg_gen = lcg(initial_seed)\n",
    "    for _ in range(20):\n",
    "        seed = next(lcg_gen)\n",
    "        total_sum += max_subarray_sum(n, seed, min_val, max_val)\n",
    "    return total_sum\n",
    "\n",
    "# 参数\n",
    "n = 10000         # 随机数数量\n",
    "initial_seed = 42 # LCG 的初始种子\n",
    "min_val = -10     # 随机数最小值\n",
    "max_val = 10      # 随机数最大值\n",
    "\n",
    "# 函数计时\n",
    "import time\n",
    "start_time = time.time()\n",
    "result = total_max_subarray_sum(n, initial_seed, min_val, max_val)\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"最大子数组总和（20次运行）：\", result)\n",
    "print(\"执行时间：{:.6f} 秒\".format(end_time - start_time))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "465d6cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from styles import CSS\n",
    "\n",
    "with gr.Blocks(css=CSS, theme=gr.themes.Monochrome(), title=f\"从 Python 移植到 {language}\") as ui:\n",
    "    with gr.Row(equal_height=True):\n",
    "        with gr.Column(scale=6):\n",
    "            python = gr.Code(\n",
    "                label=\"Python (原始)\",\n",
    "                value=python_hard,\n",
    "                language=\"python\",\n",
    "                lines=26\n",
    "            )\n",
    "        with gr.Column(scale=6):\n",
    "            cpp = gr.Code(\n",
    "                label=f\"{language} (已生成)\",\n",
    "                value=\"\",\n",
    "                language=\"cpp\",\n",
    "                lines=26\n",
    "            )\n",
    "\n",
    "    with gr.Row(elem_classes=[\"controls\"]):\n",
    "        python_run = gr.Button(\"运行 Python\", elem_classes=[\"run-btn\", \"py\"])\n",
    "        model = gr.Dropdown(models, value=models[0], show_label=False)\n",
    "        convert = gr.Button(f\"移植到 {language}\", elem_classes=[\"convert-btn\"])\n",
    "        cpp_run = gr.Button(f\"运行 {language}\", elem_classes=[\"run-btn\", \"cpp\"])\n",
    "\n",
    "    with gr.Row(equal_height=True):\n",
    "        with gr.Column(scale=6):\n",
    "            python_out = gr.TextArea(label=\"Python 结果\", lines=8, elem_classes=[\"py-out\"])\n",
    "        with gr.Column(scale=6):\n",
    "            cpp_out = gr.TextArea(label=f\"{language} 结果\", lines=8, elem_classes=[\"cpp-out\"])\n",
    "\n",
    "    convert.click(fn=port, inputs=[model, python], outputs=[cpp])\n",
    "    python_run.click(fn=run_python, inputs=[python], outputs=[python_out])\n",
    "    cpp_run.click(fn=compile_and_run, inputs=[cpp], outputs=[cpp_out])\n",
    "\n",
    "ui.launch(inbrowser=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2311ada8",
   "metadata": {},
   "source": [
    "## 结果！\n",
    "\n",
    "Qwen 2.5 Coder:失败 \n",
    "Gemini 2.5 Pro:  失败 \n",
    "DeepSeek Coder v2:   \n",
    "Qwen3 Coder 30B: 失败 \n",
    "Claude Sonnet 4.5: 0.510052 秒 \n",
    "GPT-5:   失败\n",
    "\n",
    "GPT-oss-20B: 0.000441 秒\n",
    "DeepSeek Coder v3.2-exp ：0.517202 秒\n",
    "OpenAI GPT-OSS 120B: 0.000579 秒 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9b51dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在 沉默恶魔 的实验中，GPT-OSS 120B 模型的结果比 Python 代码快 36,640 倍。\n"
     ]
    }
   ],
   "source": [
    "print(f\"在 沉默恶魔 的实验中，GPT-OSS 120B 模型的结果比 Python 代码快 {16.158406/0.000441:,.0f} 倍。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6197bb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
